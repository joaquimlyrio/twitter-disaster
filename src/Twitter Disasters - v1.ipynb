{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model, model_selection, preprocessing, metrics, svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Positive [TP] = your prediction is 1, and the ground truth is also 1 - you predicted a positive and that's true!\n",
    "# False Positive [FP] = your prediction is 1, and the ground truth is 0 - you predicted a positive, and that's false.\n",
    "# False Negative [FN] = your prediction is 0, and the ground truth is 1 - you predicted a negative, and that's false.\n",
    "\n",
    "##\n",
    "## Accuracy is measured by F1 score = 2 ∗ (precision∗recall) / (precision+recall)\n",
    "## \n",
    "## and precision = TP/(TP+FP) and recall = TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train = pd.read_csv( '../data/nlp-getting-started/train.csv' )\n",
    "test  = pd.read_csv( '../data/nlp-getting-started/test.csv' )\n",
    "subm_samp = pd.read_csv( '../data/nlp-getting-started/sample_submission.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5   8     NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6  10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...   \n",
       "7  13     NaN      NaN  I'm on top of the hill and I can see a fire in...   \n",
       "8  14     NaN      NaN  There's an emergency evacuation happening now ...   \n",
       "9  15     NaN      NaN  I'm afraid that the tornado is coming to our a...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "5       1  \n",
       "6       1  \n",
       "7       1  \n",
       "8       1  \n",
       "9       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3271\n",
      "4342\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Checking size of each class on train set\n",
    "print( train[ train['target'] == 1 ].shape[0] )\n",
    "print( train[ train['target'] == 0 ].shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',\n",
       "       'Forest fire near La Ronge Sask. Canada'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check first tweets when disaster happened\n",
    "train[train[\"target\"] == 1][\"text\"].values[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"What's up man?\", 'I love fruits'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check first tweets when disaster NOT happened\n",
    "train[train[\"target\"] == 0][\"text\"].values[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove letter case and stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Clean words: tokenize, remove stopwords and punctuation, all lowercase\n",
    "## \n",
    "## remove times etc\n",
    "##\n",
    "## Use word embeddings - GloVe trained on Twitter data already downloaded\n",
    "##\n",
    "## Think of way to convert word embedding into some type of aggregate embedding, like tweet embeddding\n",
    "##\n",
    "## Model it\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Function to process data\n",
    "###\n",
    "def textProcessing(dt, textCol):\n",
    "    \n",
    "    # Get stopwords\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    \n",
    "    # Remove cases\n",
    "    dt['tmp_text'] = dt[textCol].str.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    dt['tmp_text'] = dt.apply(lambda row: row['tmp_text'].translate(str.maketrans('', '', string.punctuation)), axis=1)\n",
    "\n",
    "    # Tokenize\n",
    "    dt['tmp_text'] = dt.apply(lambda row: word_tokenize(row['tmp_text']), axis=1)\n",
    "\n",
    "    # Remove stopwords\n",
    "    dt['new_text'] = dt['tmp_text'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "    \n",
    "    # Return dataframe\n",
    "    return dt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tmp_text</th>\n",
       "      <th>new_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
       "      <td>[deeds, reason, earthquake, may, allah, forgiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[all, residents, asked, to, shelter, in, place...</td>\n",
       "      <td>[residents, asked, shelter, place, notified, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>[13000, people, receive, wildfires, evacuation...</td>\n",
       "      <td>[13000, people, receive, wildfires, evacuation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
       "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>[two, giant, cranes, holding, a, bridge, colla...</td>\n",
       "      <td>[two, giant, cranes, holding, bridge, collapse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ariaahrary, thetawniest, the, out, of, contro...</td>\n",
       "      <td>[ariaahrary, thetawniest, control, wild, fires...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>[m194, 0104, utc5km, s, of, volcano, hawaii, h...</td>\n",
       "      <td>[m194, 0104, utc5km, volcano, hawaii, httptcoz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[police, investigating, after, an, ebike, coll...</td>\n",
       "      <td>[police, investigating, ebike, collided, car, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, latest, more, homes, razed, by, northern...</td>\n",
       "      <td>[latest, homes, razed, northern, california, w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "0     Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1                Forest fire near La Ronge Sask. Canada       1   \n",
       "2     All residents asked to 'shelter in place' are ...       1   \n",
       "3     13,000 people receive #wildfires evacuation or...       1   \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "...                                                 ...     ...   \n",
       "7608  Two giant cranes holding a bridge collapse int...       1   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1   \n",
       "7611  Police investigating after an e-bike collided ...       1   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1   \n",
       "\n",
       "                                               tmp_text  \\\n",
       "0     [our, deeds, are, the, reason, of, this, earth...   \n",
       "1         [forest, fire, near, la, ronge, sask, canada]   \n",
       "2     [all, residents, asked, to, shelter, in, place...   \n",
       "3     [13000, people, receive, wildfires, evacuation...   \n",
       "4     [just, got, sent, this, photo, from, ruby, ala...   \n",
       "...                                                 ...   \n",
       "7608  [two, giant, cranes, holding, a, bridge, colla...   \n",
       "7609  [ariaahrary, thetawniest, the, out, of, contro...   \n",
       "7610  [m194, 0104, utc5km, s, of, volcano, hawaii, h...   \n",
       "7611  [police, investigating, after, an, ebike, coll...   \n",
       "7612  [the, latest, more, homes, razed, by, northern...   \n",
       "\n",
       "                                               new_text  \n",
       "0     [deeds, reason, earthquake, may, allah, forgiv...  \n",
       "1         [forest, fire, near, la, ronge, sask, canada]  \n",
       "2     [residents, asked, shelter, place, notified, o...  \n",
       "3     [13000, people, receive, wildfires, evacuation...  \n",
       "4     [got, sent, photo, ruby, alaska, smoke, wildfi...  \n",
       "...                                                 ...  \n",
       "7608  [two, giant, cranes, holding, bridge, collapse...  \n",
       "7609  [ariaahrary, thetawniest, control, wild, fires...  \n",
       "7610  [m194, 0104, utc5km, volcano, hawaii, httptcoz...  \n",
       "7611  [police, investigating, ebike, collided, car, ...  \n",
       "7612  [latest, homes, razed, northern, california, w...  \n",
       "\n",
       "[7613 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "newtrain = textProcessing( dt=train, textCol='text')\n",
    "newtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read GloVe vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this chunk takes a bit to run\n",
    "glovePath = '/Users/joaquimlyrio/Downloads/glove/glove.twitter.27B.25d.txt'\n",
    "embeddings_dict = {}\n",
    "with open( glovePath, 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.41602 ,  0.32667 ,  0.65292 ,  0.18718 , -0.57324 , -1.1845  ,\n",
       "       -1.8769  , -0.011423,  1.2516  , -1.1869  , -0.46634 , -0.57578 ,\n",
       "       -0.8656  , -0.4988  ,  0.63822 , -1.4461  , -1.2926  ,  0.57836 ,\n",
       "        0.39184 , -0.49741 ,  0.6698  ,  0.94942 , -1.1361  , -1.1276  ,\n",
       "        0.0813  ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['joaquim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create features for each tweet based on GloVe vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict[ newtrain['new_text'][0][0] ]\n",
    "newtrain['new_text'][0]\n",
    "\n",
    "# embeddings_dict[ newtrain['new_text'] ]\n",
    "\n",
    "def computeGloVeEnsemble( s, embeddings ):\n",
    "    \n",
    "    iCnt = 0\n",
    "    cum = np.zeros( embeddings.get('cool').shape )\n",
    "    \n",
    "    # iterate over words in sentence s\n",
    "    # first word\n",
    "    if s[0] in embeddings:\n",
    "        cum = embeddings.get(s[0])\n",
    "        iCnt = iCnt + 1\n",
    "    \n",
    "    # other words\n",
    "    for w in s[1:]:\n",
    "        if w in embeddings:\n",
    "            cum = cum + embeddings.get(w)\n",
    "            iCnt = iCnt + 1\n",
    "        \n",
    "    return cum / iCnt\n",
    "\n",
    "# print(newtrain['new_text'][100])\n",
    "# computeGloVeEnsemble( newtrain['new_text'][3], embeddings=embeddings_dict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/py37_ml_lab/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# iterate over rows of train\n",
    "sentEmbed = {}\n",
    "for iRow in np.arange(0,newtrain.shape[0],1):\n",
    "    sentEmbed[iRow] = computeGloVeEnsemble( newtrain['new_text'][iRow], embeddings_dict )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7610, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.034642</td>\n",
       "      <td>0.113201</td>\n",
       "      <td>-0.430404</td>\n",
       "      <td>0.489391</td>\n",
       "      <td>-0.853268</td>\n",
       "      <td>-0.306259</td>\n",
       "      <td>1.077509</td>\n",
       "      <td>-0.201949</td>\n",
       "      <td>-0.086634</td>\n",
       "      <td>0.437167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115637</td>\n",
       "      <td>0.230185</td>\n",
       "      <td>0.121293</td>\n",
       "      <td>0.576177</td>\n",
       "      <td>-0.770221</td>\n",
       "      <td>0.263890</td>\n",
       "      <td>0.306265</td>\n",
       "      <td>-0.436617</td>\n",
       "      <td>0.242523</td>\n",
       "      <td>-0.605413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.567261</td>\n",
       "      <td>-0.202308</td>\n",
       "      <td>-0.182597</td>\n",
       "      <td>-0.002299</td>\n",
       "      <td>-0.911867</td>\n",
       "      <td>0.029404</td>\n",
       "      <td>0.044439</td>\n",
       "      <td>-0.149501</td>\n",
       "      <td>0.482768</td>\n",
       "      <td>-0.156152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251632</td>\n",
       "      <td>0.237843</td>\n",
       "      <td>0.109339</td>\n",
       "      <td>0.164636</td>\n",
       "      <td>0.505321</td>\n",
       "      <td>0.013704</td>\n",
       "      <td>-0.441899</td>\n",
       "      <td>0.354123</td>\n",
       "      <td>-0.906471</td>\n",
       "      <td>0.207224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.600594</td>\n",
       "      <td>0.683745</td>\n",
       "      <td>-0.279191</td>\n",
       "      <td>-0.182460</td>\n",
       "      <td>-0.222019</td>\n",
       "      <td>-0.768375</td>\n",
       "      <td>0.441783</td>\n",
       "      <td>-1.233742</td>\n",
       "      <td>0.358456</td>\n",
       "      <td>0.232217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012621</td>\n",
       "      <td>0.572267</td>\n",
       "      <td>-0.258214</td>\n",
       "      <td>0.147398</td>\n",
       "      <td>-0.713238</td>\n",
       "      <td>0.231145</td>\n",
       "      <td>-0.565903</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>-0.839046</td>\n",
       "      <td>-0.239976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.302245</td>\n",
       "      <td>0.713562</td>\n",
       "      <td>-0.572892</td>\n",
       "      <td>0.051555</td>\n",
       "      <td>-0.331429</td>\n",
       "      <td>-0.620134</td>\n",
       "      <td>0.610448</td>\n",
       "      <td>-1.426075</td>\n",
       "      <td>0.374652</td>\n",
       "      <td>0.257453</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229748</td>\n",
       "      <td>0.337154</td>\n",
       "      <td>-0.285332</td>\n",
       "      <td>0.569386</td>\n",
       "      <td>-0.700277</td>\n",
       "      <td>-0.067718</td>\n",
       "      <td>-0.516196</td>\n",
       "      <td>0.041319</td>\n",
       "      <td>-0.958743</td>\n",
       "      <td>-0.079488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.440428</td>\n",
       "      <td>0.247316</td>\n",
       "      <td>0.190015</td>\n",
       "      <td>0.146781</td>\n",
       "      <td>-0.571416</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.602678</td>\n",
       "      <td>-0.746124</td>\n",
       "      <td>0.165429</td>\n",
       "      <td>0.126911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120295</td>\n",
       "      <td>0.539177</td>\n",
       "      <td>-0.081443</td>\n",
       "      <td>-0.047724</td>\n",
       "      <td>0.087765</td>\n",
       "      <td>0.124569</td>\n",
       "      <td>-0.118026</td>\n",
       "      <td>0.481347</td>\n",
       "      <td>-0.423808</td>\n",
       "      <td>0.124419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>-0.648327</td>\n",
       "      <td>0.070490</td>\n",
       "      <td>0.380065</td>\n",
       "      <td>-0.042914</td>\n",
       "      <td>-0.387247</td>\n",
       "      <td>0.036434</td>\n",
       "      <td>0.478167</td>\n",
       "      <td>-1.198946</td>\n",
       "      <td>0.579818</td>\n",
       "      <td>0.453287</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100243</td>\n",
       "      <td>0.376008</td>\n",
       "      <td>-0.045428</td>\n",
       "      <td>0.473099</td>\n",
       "      <td>-0.313125</td>\n",
       "      <td>-0.304531</td>\n",
       "      <td>-0.226257</td>\n",
       "      <td>0.297763</td>\n",
       "      <td>-1.010939</td>\n",
       "      <td>-0.234808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>-0.135133</td>\n",
       "      <td>0.096568</td>\n",
       "      <td>-0.276388</td>\n",
       "      <td>-0.126443</td>\n",
       "      <td>-0.288394</td>\n",
       "      <td>0.141316</td>\n",
       "      <td>0.764192</td>\n",
       "      <td>-0.630848</td>\n",
       "      <td>0.299536</td>\n",
       "      <td>-0.072727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019655</td>\n",
       "      <td>0.220042</td>\n",
       "      <td>0.173761</td>\n",
       "      <td>0.262831</td>\n",
       "      <td>-0.165517</td>\n",
       "      <td>0.061640</td>\n",
       "      <td>-0.072648</td>\n",
       "      <td>0.181287</td>\n",
       "      <td>-0.851537</td>\n",
       "      <td>-0.043328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>-1.168000</td>\n",
       "      <td>-0.450815</td>\n",
       "      <td>0.532550</td>\n",
       "      <td>-0.399675</td>\n",
       "      <td>-1.363600</td>\n",
       "      <td>-0.095002</td>\n",
       "      <td>0.954495</td>\n",
       "      <td>-0.814990</td>\n",
       "      <td>0.556580</td>\n",
       "      <td>0.270772</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002895</td>\n",
       "      <td>0.338860</td>\n",
       "      <td>0.395045</td>\n",
       "      <td>1.074420</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>-0.702900</td>\n",
       "      <td>-0.445012</td>\n",
       "      <td>0.069295</td>\n",
       "      <td>-1.341100</td>\n",
       "      <td>0.638075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>-0.287354</td>\n",
       "      <td>0.493432</td>\n",
       "      <td>-0.094455</td>\n",
       "      <td>-0.263650</td>\n",
       "      <td>0.140191</td>\n",
       "      <td>-0.228304</td>\n",
       "      <td>0.218582</td>\n",
       "      <td>-0.772906</td>\n",
       "      <td>0.312802</td>\n",
       "      <td>-0.002916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336800</td>\n",
       "      <td>0.562909</td>\n",
       "      <td>0.074350</td>\n",
       "      <td>0.353500</td>\n",
       "      <td>-0.345130</td>\n",
       "      <td>0.084602</td>\n",
       "      <td>0.363871</td>\n",
       "      <td>0.330678</td>\n",
       "      <td>-0.892794</td>\n",
       "      <td>-0.284000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>-0.210782</td>\n",
       "      <td>0.028216</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>-0.517072</td>\n",
       "      <td>-0.337078</td>\n",
       "      <td>-0.333011</td>\n",
       "      <td>0.361668</td>\n",
       "      <td>-0.830756</td>\n",
       "      <td>0.631351</td>\n",
       "      <td>0.048237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.513970</td>\n",
       "      <td>0.231099</td>\n",
       "      <td>0.292712</td>\n",
       "      <td>0.611585</td>\n",
       "      <td>-0.013370</td>\n",
       "      <td>-0.244303</td>\n",
       "      <td>-0.745605</td>\n",
       "      <td>-0.096155</td>\n",
       "      <td>-1.403071</td>\n",
       "      <td>0.199998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7610 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -0.034642  0.113201 -0.430404  0.489391 -0.853268 -0.306259  1.077509   \n",
       "1    -0.567261 -0.202308 -0.182597 -0.002299 -0.911867  0.029404  0.044439   \n",
       "2    -0.600594  0.683745 -0.279191 -0.182460 -0.222019 -0.768375  0.441783   \n",
       "3    -0.302245  0.713562 -0.572892  0.051555 -0.331429 -0.620134  0.610448   \n",
       "4    -0.440428  0.247316  0.190015  0.146781 -0.571416  0.001253  0.602678   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7608 -0.648327  0.070490  0.380065 -0.042914 -0.387247  0.036434  0.478167   \n",
       "7609 -0.135133  0.096568 -0.276388 -0.126443 -0.288394  0.141316  0.764192   \n",
       "7610 -1.168000 -0.450815  0.532550 -0.399675 -1.363600 -0.095002  0.954495   \n",
       "7611 -0.287354  0.493432 -0.094455 -0.263650  0.140191 -0.228304  0.218582   \n",
       "7612 -0.210782  0.028216 -0.000312 -0.517072 -0.337078 -0.333011  0.361668   \n",
       "\n",
       "            7         8         9   ...        15        16        17  \\\n",
       "0    -0.201949 -0.086634  0.437167  ... -0.115637  0.230185  0.121293   \n",
       "1    -0.149501  0.482768 -0.156152  ...  0.251632  0.237843  0.109339   \n",
       "2    -1.233742  0.358456  0.232217  ...  0.012621  0.572267 -0.258214   \n",
       "3    -1.426075  0.374652  0.257453  ... -0.229748  0.337154 -0.285332   \n",
       "4    -0.746124  0.165429  0.126911  ...  0.120295  0.539177 -0.081443   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7608 -1.198946  0.579818  0.453287  ... -0.100243  0.376008 -0.045428   \n",
       "7609 -0.630848  0.299536 -0.072727  ... -0.019655  0.220042  0.173761   \n",
       "7610 -0.814990  0.556580  0.270772  ... -0.002895  0.338860  0.395045   \n",
       "7611 -0.772906  0.312802 -0.002916  ...  0.336800  0.562909  0.074350   \n",
       "7612 -0.830756  0.631351  0.048237  ... -0.513970  0.231099  0.292712   \n",
       "\n",
       "            18        19        20        21        22        23        24  \n",
       "0     0.576177 -0.770221  0.263890  0.306265 -0.436617  0.242523 -0.605413  \n",
       "1     0.164636  0.505321  0.013704 -0.441899  0.354123 -0.906471  0.207224  \n",
       "2     0.147398 -0.713238  0.231145 -0.565903  0.002023 -0.839046 -0.239976  \n",
       "3     0.569386 -0.700277 -0.067718 -0.516196  0.041319 -0.958743 -0.079488  \n",
       "4    -0.047724  0.087765  0.124569 -0.118026  0.481347 -0.423808  0.124419  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7608  0.473099 -0.313125 -0.304531 -0.226257  0.297763 -1.010939 -0.234808  \n",
       "7609  0.262831 -0.165517  0.061640 -0.072648  0.181287 -0.851537 -0.043328  \n",
       "7610  1.074420  0.028868 -0.702900 -0.445012  0.069295 -1.341100  0.638075  \n",
       "7611  0.353500 -0.345130  0.084602  0.363871  0.330678 -0.892794 -0.284000  \n",
       "7612  0.611585 -0.013370 -0.244303 -0.745605 -0.096155 -1.403071  0.199998  \n",
       "\n",
       "[7610 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gloveTrain = pd.DataFrame.from_dict(sentEmbed, orient = 'index')\n",
    "gloveTrain['target'] = newtrain['target']\n",
    "gloveTrain = gloveTrain.dropna()\n",
    "gloveTrain.shape\n",
    "\n",
    "gloveTarget = gloveTrain['target']\n",
    "\n",
    "gloveTrain = pd.DataFrame.from_dict(sentEmbed, orient = 'index')\n",
    "gloveTrain = gloveTrain.dropna()\n",
    "print(gloveTrain.shape)\n",
    "\n",
    "gloveTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 21637)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "##\n",
    "## Count words\n",
    "count_vect = CountVectorizer()\n",
    "train_counts = count_vect.fit_transform(train.text)\n",
    "train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 21637)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "##\n",
    "## TF-IDF\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "train_tfidf = tfidf_transformer.fit_transform(train_counts)\n",
    "train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Tf-idf + Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## Fit Bernoulli Naive-Bayes\n",
    "clf_tfidf = BernoulliNB().fit(train_tfidf, train.target)\n",
    "clf_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8943911729935636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8658658658658658"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "##\n",
    "## Predict on train set\n",
    "nObs = train_tfidf.shape[0]\n",
    "print( np.mean( clf_tfidf.predict(train_tfidf[0:nObs]) == train.target[0:nObs] ) )\n",
    "metrics.f1_score( y_true = clf_tfidf.predict(train_tfidf[0:nObs]),\n",
    "                  y_pred = train.target[0:nObs] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BernoulliNB: [0.63339383 0.62758051 0.68714632 0.64700781 0.76566125]'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Bernoulli NB\n",
    "clf1 = BernoulliNB()\n",
    "scores_tfidf = cross_val_score(clf1, train_tfidf, train.target, cv=5, scoring='f1')\n",
    "f'BernoulliNB: {scores_tfidf}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) GloVe Ensemble + Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7336399474375821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7016045929633445"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_glove = BernoulliNB().fit(gloveTrain, gloveTarget)\n",
    "clf_glove\n",
    "\n",
    "\n",
    "##\n",
    "## Predict on train set\n",
    "nObs = gloveTrain.shape[0]\n",
    "print( np.mean( clf_glove.predict(gloveTrain[0:nObs]) == gloveTarget[0:nObs] ) )\n",
    "metrics.f1_score( y_true = clf_glove.predict(gloveTrain[0:nObs]),\n",
    "                  y_pred = gloveTarget[0:nObs] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BernoulliNB: [0.68663968 0.68019594 0.69257951 0.68864469 0.73676471]'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Bernoulli NB\n",
    "clf1 = BernoulliNB()\n",
    "scores_glove = cross_val_score(clf1, gloveTrain, gloveTarget, cv=5, scoring='f1')\n",
    "f'BernoulliNB: {scores_glove}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## RandomForestClassifier\n",
    "# clf2 = RandomForestClassifier()\n",
    "# scores2 = cross_val_score(clf2, gloveTrain, gloveTarget, cv=5, scoring='f1')\n",
    "# f'RandomForestClassifier: {scores2}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Tf-Idf + Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=RidgeClassifier(alpha=1.0, class_weight=None,\n",
       "                                       copy_X=True, fit_intercept=True,\n",
       "                                       max_iter=None, normalize=False,\n",
       "                                       random_state=None, solver='auto',\n",
       "                                       tol=0.001),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'alpha': [0, 0.25, 0.5, 0.75, 1.0]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## Obs: this cell takes a while to run ~ 3 min or so\n",
    "##\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "## RidgeClassifier\n",
    "ridge = linear_model.RidgeClassifier()\n",
    "ridge.get_params()\n",
    "\n",
    "# define parameter range to perform GridSearchCV\n",
    "param_grid = [ {'alpha': np.arange(0,1.1,.1)} ]\n",
    "\n",
    "# Split the dataset for cross validation\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(train_tfidf, \n",
    "                                                          train.target, \n",
    "                                                          test_size=0.2, \n",
    "                                                          random_state=0)\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameter = [{'alpha':[0,.25,.5,.75,1.0]}]\n",
    "\n",
    "# Score to to optimize over\n",
    "score = 'f1'\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    RidgeClassifier(), tuned_parameter, scoring=score\n",
    ")\n",
    "\n",
    "clf.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 0.75}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.409 (+/-0.161) for {'alpha': 0}\n",
      "0.737 (+/-0.018) for {'alpha': 0.25}\n",
      "0.745 (+/-0.025) for {'alpha': 0.5}\n",
      "0.751 (+/-0.032) for {'alpha': 0.75}\n",
      "0.750 (+/-0.032) for {'alpha': 1.0}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85       886\n",
      "           1       0.83      0.69      0.75       637\n",
      "\n",
      "    accuracy                           0.81      1523\n",
      "   macro avg       0.81      0.79      0.80      1523\n",
      "weighted avg       0.81      0.81      0.81      1523\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test_tfidf)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### (4) GloVe + Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=RidgeClassifier(alpha=1.0, class_weight=None,\n",
       "                                       copy_X=True, fit_intercept=True,\n",
       "                                       max_iter=None, normalize=False,\n",
       "                                       random_state=None, solver='auto',\n",
       "                                       tol=0.001),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'alpha': [0, 0.25, 0.5, 0.75, 1.0]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## Obs: this cell takes a while to run ~ 3 min or so\n",
    "##\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "## RidgeClassifier\n",
    "ridge = linear_model.RidgeClassifier()\n",
    "ridge.get_params()\n",
    "\n",
    "# define parameter range to perform GridSearchCV\n",
    "param_grid = [ {'alpha': np.arange(0,1.1,.1)} ]\n",
    "\n",
    "# Split the dataset for cross validation\n",
    "X_train_glove, X_test_glove, y_train, y_test = train_test_split(gloveTrain, \n",
    "                                                          gloveTarget, \n",
    "                                                          test_size=0.2, \n",
    "                                                          random_state=0)\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameter = [{'alpha':[0,.25,.5,.75,1.0]}]\n",
    "\n",
    "# Score to to optimize over\n",
    "score = 'f1'\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    RidgeClassifier(), tuned_parameter, scoring=score\n",
    ")\n",
    "\n",
    "clf.fit(X_train_glove, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 0}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.724 (+/-0.035) for {'alpha': 0}\n",
      "0.724 (+/-0.035) for {'alpha': 0.25}\n",
      "0.724 (+/-0.035) for {'alpha': 0.5}\n",
      "0.724 (+/-0.035) for {'alpha': 0.75}\n",
      "0.724 (+/-0.035) for {'alpha': 1.0}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.80       890\n",
      "           1       0.75      0.64      0.69       632\n",
      "\n",
      "    accuracy                           0.76      1522\n",
      "   macro avg       0.76      0.74      0.75      1522\n",
      "weighted avg       0.76      0.76      0.76      1522\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test_glove)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) GloVe + Feed-Forward Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tensorflow.keras import backend as K\n",
    "\n",
    "# def recall_m(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#     recall = true_positives / (possible_positives + K.epsilon())\n",
    "#     return recall\n",
    "\n",
    "# def precision_m(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#     precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#     return precision\n",
    "\n",
    "# def f1_m(y_true, y_pred):\n",
    "#     precision = precision_m(y_true, y_pred)\n",
    "#     recall = recall_m(y_true, y_pred)\n",
    "#     return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# define NN architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "# optimizes and loss function\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6088, 25)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_glove.to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6088 samples\n",
      "Epoch 1/30\n",
      "6088/6088 [==============================] - 0s 66us/sample - loss: 0.5238 - accuracy: 0.7511\n",
      "Epoch 2/30\n",
      "6088/6088 [==============================] - 0s 32us/sample - loss: 0.4640 - accuracy: 0.7870\n",
      "Epoch 3/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4543 - accuracy: 0.7922\n",
      "Epoch 4/30\n",
      "6088/6088 [==============================] - 0s 32us/sample - loss: 0.4489 - accuracy: 0.7940\n",
      "Epoch 5/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4459 - accuracy: 0.8016\n",
      "Epoch 6/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4422 - accuracy: 0.7986\n",
      "Epoch 7/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4397 - accuracy: 0.8044\n",
      "Epoch 8/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4368 - accuracy: 0.8040\n",
      "Epoch 9/30\n",
      "6088/6088 [==============================] - 0s 32us/sample - loss: 0.4334 - accuracy: 0.8045\n",
      "Epoch 10/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4327 - accuracy: 0.8057\n",
      "Epoch 11/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4292 - accuracy: 0.8065\n",
      "Epoch 12/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4269 - accuracy: 0.8080\n",
      "Epoch 13/30\n",
      "6088/6088 [==============================] - 0s 32us/sample - loss: 0.4248 - accuracy: 0.8096\n",
      "Epoch 14/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4242 - accuracy: 0.8081\n",
      "Epoch 15/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4234 - accuracy: 0.8103\n",
      "Epoch 16/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4206 - accuracy: 0.8146\n",
      "Epoch 17/30\n",
      "6088/6088 [==============================] - 0s 32us/sample - loss: 0.4187 - accuracy: 0.8118\n",
      "Epoch 18/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4176 - accuracy: 0.8123\n",
      "Epoch 19/30\n",
      "6088/6088 [==============================] - 0s 32us/sample - loss: 0.4161 - accuracy: 0.8134\n",
      "Epoch 20/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4139 - accuracy: 0.8170\n",
      "Epoch 21/30\n",
      "6088/6088 [==============================] - 0s 32us/sample - loss: 0.4110 - accuracy: 0.8173\n",
      "Epoch 22/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4116 - accuracy: 0.8164\n",
      "Epoch 23/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4106 - accuracy: 0.8150\n",
      "Epoch 24/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4078 - accuracy: 0.8169\n",
      "Epoch 25/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4070 - accuracy: 0.8182\n",
      "Epoch 26/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4064 - accuracy: 0.8183\n",
      "Epoch 27/30\n",
      "6088/6088 [==============================] - 0s 31us/sample - loss: 0.4039 - accuracy: 0.8198\n",
      "Epoch 28/30\n",
      "6088/6088 [==============================] - 0s 33us/sample - loss: 0.4051 - accuracy: 0.8205\n",
      "Epoch 29/30\n",
      "6088/6088 [==============================] - 0s 33us/sample - loss: 0.4038 - accuracy: 0.8226\n",
      "Epoch 30/30\n",
      "6088/6088 [==============================] - 0s 33us/sample - loss: 0.3994 - accuracy: 0.8229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a52e21e50>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_glove.to_numpy(), y_train.to_numpy(), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1522/1522 - 0s - loss: 0.4900 - accuracy: 0.7858\n",
      "\n",
      "Test accuracy: 0.78580815\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test_glove.to_numpy(),  y_test.to_numpy(), verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1522,)\n",
      "(1522, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78580814717477"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "\n",
    "predictions = probability_model.predict(X_test_glove.to_numpy())\n",
    "\n",
    "print(y_test.shape)\n",
    "print(predictions.shape)\n",
    "\n",
    "def argmax(a):\n",
    "    return np.argmax(a)\n",
    "\n",
    "preds_argmax = np.apply_along_axis(argmax, 1, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7120141342756183"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = np.sum(np.round(np.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives)\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = np.sum(np.round(np.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives)\n",
    "    return precision\n",
    "\n",
    "# def f1(y_true, y_pred):\n",
    "#     precision = precision(y_true, y_pred)\n",
    "#     recall = recall(y_true, y_pred)\n",
    "#     return 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "\n",
    "prec = precision( y_test, preds_argmax )\n",
    "reca = recall( y_test, preds_argmax )\n",
    "f1   = 2*((prec*reca)/(prec+reca))\n",
    "f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
