{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import linear_model, model_selection, preprocessing, metrics, svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "from plotnine import *\n",
    "\n",
    "# tensorflow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# module_url = \"https://tfhub.dev/google/nnlm-en-dim128/2\"\n",
    "# embed = hub.KerasLayer(module_url)\n",
    "# embeddings = embed([\"A long sentence.\", \"single-word\",\n",
    "#                   \"http://example.com\"])\n",
    "# print(embeddings.shape)  #(3,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "train = pd.read_csv( '../data/nlp-getting-started/train.csv' )\n",
    "test  = pd.read_csv( '../data/nlp-getting-started/test.csv' )\n",
    "subm_samp = pd.read_csv( '../data/nlp-getting-started/sample_submission.csv' )\n",
    "\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3271\n",
      "4342\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Checking size of each class on train set\n",
    "print( train[ train['target'] == 1 ].shape[0] )\n",
    "print( train[ train['target'] == 0 ].shape[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Function to process data\n",
    "###\n",
    "def textProcessing(dt, textCol):\n",
    "    \n",
    "    # make copy\n",
    "    dt_copy = dt.copy()\n",
    "    \n",
    "    # Get stopwords\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    \n",
    "    # Remove cases\n",
    "    dt_copy['tmp_text'] = dt[textCol].str.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    dt_copy['tmp_text'] = dt_copy.apply(lambda row: row['tmp_text'].translate(str.maketrans('', '', string.punctuation)), axis=1)\n",
    "\n",
    "    # Tokenize\n",
    "    dt_copy['tmp_text'] = dt_copy.apply(lambda row: word_tokenize(row['tmp_text']), axis=1)\n",
    "\n",
    "    # Remove stopwords\n",
    "    dt_copy['new_text'] = dt_copy['tmp_text'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "    \n",
    "    # Return dataframe\n",
    "    return dt_copy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Load pre-trained sentence embedding - Google's Swivel\n",
    "model = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(model, output_shape=[20], input_shape=[], \n",
    "#                            dtype=tf.string, trainable=False)\n",
    "                           dtype=tf.string, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 20)                400020    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 400,373\n",
      "Trainable params: 400,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Define model's architecture\n",
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = train['text']\n",
    "Y_train_all = train['target']\n",
    "\n",
    "# Separate in test/train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_train_all, Y_train_all, test_size=0.3, random_state=710)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5329 samples, validate on 2284 samples\n",
      "Epoch 1/10\n",
      "5329/5329 [==============================] - 1s 210us/sample - loss: 0.6415 - accuracy: 0.6256 - val_loss: 0.5415 - val_accuracy: 0.7399\n",
      "Epoch 2/10\n",
      "5329/5329 [==============================] - 1s 117us/sample - loss: 0.5196 - accuracy: 0.7544 - val_loss: 0.5031 - val_accuracy: 0.7697\n",
      "Epoch 3/10\n",
      "5329/5329 [==============================] - 1s 117us/sample - loss: 0.4760 - accuracy: 0.7838 - val_loss: 0.4876 - val_accuracy: 0.7780\n",
      "Epoch 4/10\n",
      "5329/5329 [==============================] - 1s 117us/sample - loss: 0.4395 - accuracy: 0.8069 - val_loss: 0.4778 - val_accuracy: 0.7885\n",
      "Epoch 5/10\n",
      "5329/5329 [==============================] - 1s 114us/sample - loss: 0.4057 - accuracy: 0.8249 - val_loss: 0.4731 - val_accuracy: 0.7903\n",
      "Epoch 6/10\n",
      "5329/5329 [==============================] - 1s 116us/sample - loss: 0.3709 - accuracy: 0.8420 - val_loss: 0.4720 - val_accuracy: 0.7850\n",
      "Epoch 7/10\n",
      "5329/5329 [==============================] - 1s 119us/sample - loss: 0.3367 - accuracy: 0.8578 - val_loss: 0.4763 - val_accuracy: 0.7846\n",
      "Epoch 8/10\n",
      "5329/5329 [==============================] - 1s 118us/sample - loss: 0.3028 - accuracy: 0.8761 - val_loss: 0.4833 - val_accuracy: 0.7828\n",
      "Epoch 9/10\n",
      "5329/5329 [==============================] - 1s 120us/sample - loss: 0.2712 - accuracy: 0.8929 - val_loss: 0.4999 - val_accuracy: 0.7780\n",
      "Epoch 10/10\n",
      "5329/5329 [==============================] - 1s 120us/sample - loss: 0.2403 - accuracy: 0.9052 - val_loss: 0.5172 - val_accuracy: 0.7750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10eaa9410>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train Model\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          validation_data=(X_test, y_test),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2284/2284 [==============================] - 0s 55us/sample - loss: 0.5172 - accuracy: 0.7750\n",
      "[0.5172323067321878, 0.7749562]\n"
     ]
    }
   ],
   "source": [
    "# get predictions for out of sample\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# get metrics\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7281153450051493\n",
      "0.7387669801462905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7334024896265561"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = np.sum(np.round(np.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives)\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = np.sum(np.round(np.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives)\n",
    "    return precision\n",
    "\n",
    "prec = precision( np.reshape(y_test.to_numpy(), (-1, 1)), np.round(predictions) )\n",
    "reca = recall( np.reshape(y_test.to_numpy(), (-1, 1)), np.round(predictions) )\n",
    "f1   = 2*((prec*reca)/(prec+reca))\n",
    "print(prec)\n",
    "print(reca)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf + Bernoulli Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##\n",
    "## Count words\n",
    "count_vect = CountVectorizer()\n",
    "train_counts = count_vect.fit_transform(train.text)\n",
    "train_counts.shape\n",
    "\n",
    "\n",
    "##\n",
    "## TF-IDF\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "train_tfidf = tfidf_transformer.fit_transform(train_counts)\n",
    "train_tfidf.shape\n",
    "\n",
    "##\n",
    "## Fit Bernoulli Naive-Bayes\n",
    "clf_tfidf = BernoulliNB().fit(train_tfidf, train.target)\n",
    "clf_tfidf\n",
    "\n",
    "\n",
    "##\n",
    "## Predict on train set\n",
    "nObs = train_tfidf.shape[0]\n",
    "print( np.mean( clf_tfidf.predict(train_tfidf[0:nObs]) == train.target[0:nObs] ) )\n",
    "metrics.f1_score( y_true = clf_tfidf.predict(train_tfidf[0:nObs]),\n",
    "                  y_pred = train.target[0:nObs] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37_ml_lab] *",
   "language": "python",
   "name": "conda-env-py37_ml_lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
