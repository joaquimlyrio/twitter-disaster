{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Disaster Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import linear_model, model_selection, preprocessing, metrics, svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "from plotnine import *\n",
    "\n",
    "# tensorflow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "train = pd.read_csv( '../data/nlp-getting-started/train.csv' )\n",
    "test  = pd.read_csv( '../data/nlp-getting-started/test.csv' )\n",
    "subm_samp = pd.read_csv( '../data/nlp-getting-started/sample_submission.csv' )\n",
    "\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Class 1 Size : 3271\n",
      " Class 0 Size : 4342\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Checking size of each class on train set\n",
    "print( ' Class 1 Size : ' + str(train[ train['target'] == 1 ].shape[0]) )\n",
    "print( ' Class 0 Size : ' + str(train[ train['target'] == 0 ].shape[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>new_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>[deeds, reason, earthquake, may, allah, forgiv...</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>[residents, asked, shelter, place, notified, o...</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>[13000, people, receive, wildfires, evacuation...</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword                                               text  \\\n",
       "0   1     NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [deeds, reason, earthquake, may, allah, forgiv...   \n",
       "1      [forest, fire, near, la, ronge, sask, canada]   \n",
       "2  [residents, asked, shelter, place, notified, o...   \n",
       "3  [13000, people, receive, wildfires, evacuation...   \n",
       "4  [got, sent, photo, ruby, alaska, smoke, wildfi...   \n",
       "\n",
       "                                            new_text  target  \n",
       "0       deeds reason earthquake may allah forgive us       1  \n",
       "1              forest fire near la ronge sask canada       1  \n",
       "2  residents asked shelter place notified officer...       1  \n",
       "3  13000 people receive wildfires evacuation orde...       1  \n",
       "4  got sent photo ruby alaska smoke wildfires pou...       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### Function to process data\n",
    "###\n",
    "def textProcessing(dt, textCol, cols = ['id','keyword','text','tokenized','new_text','target'] ):\n",
    "    \n",
    "    # make copy\n",
    "    dt_copy = dt.copy()\n",
    "    \n",
    "    # Get stopwords\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    \n",
    "    # Remove cases\n",
    "    dt_copy['tmp_text'] = dt[textCol].str.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    dt_copy['tmp_text'] = dt_copy.apply(lambda row: row['tmp_text'].translate(str.maketrans('', '', string.punctuation)), axis=1)\n",
    "\n",
    "    # Tokenize\n",
    "    dt_copy['tmp_text'] = dt_copy.apply(lambda row: word_tokenize(row['tmp_text']), axis=1)\n",
    "\n",
    "    # Remove stopwords\n",
    "    dt_copy['tokenized'] = dt_copy['tmp_text'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "    \n",
    "    # Merge words\n",
    "    dt_copy['new_text'] = dt_copy['tokenized'].apply( lambda row: ' '.join(row) )\n",
    "    \n",
    "    # Return dataframe\n",
    "    return dt_copy[ cols ]\n",
    "\n",
    "newtrain = textProcessing( train, 'text' )\n",
    "newtrain.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train / Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:(5709,)\n",
      "Proportion of class 0 in train: 56.84%\n",
      "Proportion of class 1 in train: 43.16%\n",
      "\n",
      "Test shape:(1904,)\n",
      "Proportion of class 0 in train: 57.62%\n",
      "Proportion of class 1 in train: 42.38%\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset for cross validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(newtrain.new_text, \n",
    "                                                    newtrain.target, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=123)\n",
    "\n",
    "\n",
    "print('Train shape:' + str(X_train.shape) )\n",
    "print('Proportion of class 0 in train: ' + str( np.round( 100*np.sum(y_train==0) / len(y_train), 2 ) ) + '%' )\n",
    "print('Proportion of class 1 in train: ' + str( np.round( 100*np.sum(y_train==1) / len(y_train), 2 ) ) + '%' )\n",
    "print('')\n",
    "print('Test shape:' + str(X_test.shape) )\n",
    "print('Proportion of class 0 in train: ' + str( np.round( 100*np.sum(y_test==0) / len(y_test), 2 ) ) + '%' )\n",
    "print('Proportion of class 1 in train: ' + str( np.round( 100*np.sum(y_test==1) / len(y_test), 2 ) ) + '%' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf + Bernoulli Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5709, 18221)\n",
      "(1904, 18221)\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### TF-IDF\n",
    "###\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# create Tfidf based on clean train data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform( X_train )\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "# tranform test data into Tfidf\n",
    "X_test_tfidf = vectorizer.transform( X_test )\n",
    "print(X_test_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0/1 Accuracy: 0.9164477141355754\n",
      "Test 0/1 Accuracy: 0.8025210084033614\n",
      "\n",
      "Train F1 Score: 0.895049504950495\n",
      "Test F1 Score: 0.7251461988304094\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##\n",
    "## Fit Bernoulli Naive-Bayes\n",
    "clf_tfidf = BernoulliNB().fit( X_train_tfidf, y_train )\n",
    "clf_tfidf\n",
    "\n",
    "##\n",
    "## Predict on train / test set\n",
    "print( 'Train 0/1 Accuracy: ' + str( np.mean( clf_tfidf.predict(X_train_tfidf) == y_train ) ) )\n",
    "print( 'Test 0/1 Accuracy: ' + str( np.mean( clf_tfidf.predict(X_test_tfidf) == y_test ) ) )\n",
    "print('')\n",
    "print( 'Train F1 Score: ' + str( metrics.f1_score( y_true = np.reshape(y_train.to_numpy(), (-1, 1)),\n",
    "                                                   y_pred = clf_tfidf.predict(X_train_tfidf) ) ) )\n",
    "print( 'Test F1 Score: ' + str( metrics.f1_score( y_true = np.reshape(y_test.to_numpy(), (-1, 1)),\n",
    "                                                  y_pred = clf_tfidf.predict(X_test_tfidf) ) ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf + Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge Classifier\n",
      "\n",
      "Train 0/1 Accuracy: 0.9719740760203188\n",
      "Test 0/1 Accuracy: 0.7878151260504201\n",
      "\n",
      "Train F1 Score: 0.966914805624483\n",
      "Test F1 Score: 0.7352555701179555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "print('')\n",
    "print('Ridge Classifier')\n",
    "print('')\n",
    "\n",
    "clf_ridge_tfidf = RidgeClassifierCV( alphas=[1e-3, 1e-2, 1e-1, 1, 5, 10], \n",
    "                              cv = 5 ).fit(X_train_tfidf, y_train)\n",
    "\n",
    "print( 'Train 0/1 Accuracy: ' + str( np.mean( clf_ridge_tfidf.predict(X_train_tfidf) == y_train ) ) )\n",
    "print( 'Test 0/1 Accuracy: ' + str( np.mean( clf_ridge_tfidf.predict(X_test_tfidf) == y_test ) ) )\n",
    "print('')\n",
    "print( 'Train F1 Score: ' + str( metrics.f1_score( y_true = np.reshape(y_train.to_numpy(), (-1, 1)),\n",
    "                                                   y_pred = clf_ridge_tfidf.predict(X_train_tfidf) ) ) )\n",
    "print( 'Test F1 Score: ' + str( metrics.f1_score( y_true = np.reshape(y_test.to_numpy(), (-1, 1)),\n",
    "                                                  y_pred = clf_ridge_tfidf.predict(X_test_tfidf) ) ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [ 200, 300]#, 400, 500 ]\n",
    "\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['auto', 40, 50]\n",
    "\n",
    "# # Create the random grid\n",
    "# param_grid = {'n_estimators': n_estimators,\n",
    "#               'max_features': max_features }\n",
    "\n",
    "# # Use the random grid to search for best hyperparameters\n",
    "# # First create the base model to tune\n",
    "# rf = RandomForestClassifier()\n",
    "# rf_tuned = GridSearchCV(estimator = rf, \n",
    "#                         param_grid = param_grid, \n",
    "#                         scoring = 'f1',\n",
    "#                         cv = 3, verbose= 2, n_jobs = -1 )\n",
    "\n",
    "# # Fit the random search model\n",
    "# rf_tuned.fit( X_train_tfidf, y_train )\n",
    "\n",
    "# # Print best parameters\n",
    "# rf_tuned.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( 'Train 0/1 Accuracy: ' + str( np.mean( rf_random.predict(X_train_tfidf) == y_train ) ) )\n",
    "# print( 'Test 0/1 Accuracy: ' + str( np.mean( rf_random.predict(X_test_tfidf) == y_test ) ) )\n",
    "# print('')\n",
    "# print( 'Train F1 Score: ' + str( metrics.f1_score( y_true = np.reshape(y_train.to_numpy(), (-1, 1)),\n",
    "#                                                    y_pred = rf_random.predict(X_train_tfidf) ) ) )\n",
    "# print( 'Test F1 Score: ' + str( metrics.f1_score( y_true = np.reshape(y_test.to_numpy(), (-1, 1)),\n",
    "#                                                   y_pred = rf_random.predict(X_test_tfidf) ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal Sentence Enconder + Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "embeddings = embed([\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"I am a sentence for which I would like to get its embedding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding based on clean version of text\n",
    "# X_train_embed = embed( X_train )\n",
    "# X_test_embed = embed( X_test )\n",
    "\n",
    "X_train_embed = embed( X_train )\n",
    "X_test_embed = embed( X_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge Classifier\n",
      "\n",
      "Train 0/1 Accuracy: 0.8237870029777544\n",
      "Test 0/1 Accuracy: 0.8025210084033614\n",
      "\n",
      "Train F1 Score: 0.7858663260962111\n",
      "Test F1 Score: 0.7577319587628866\n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "\n",
      "Train 0/1 Accuracy: 0.7777193904361535\n",
      "Test 0/1 Accuracy: 0.7689075630252101\n",
      "\n",
      "Train F1 Score: 0.7443078782994156\n",
      "Test F1 Score: 0.7280593325092708\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "print('')\n",
    "print('Ridge Classifier')\n",
    "print('')\n",
    "\n",
    "clf_ridge = RidgeClassifierCV( alphas=[1e-3, 1e-2, 1e-1, 1, 5, 10], \n",
    "                              cv = 5 ).fit(X_train_embed, y_train)\n",
    "\n",
    "print( 'Train 0/1 Accuracy: ' + str( np.mean( clf_ridge.predict(X_train_embed) == y_train ) ) )\n",
    "print( 'Test 0/1 Accuracy: ' + str( np.mean( clf_ridge.predict(X_test_embed) == y_test ) ) )\n",
    "print('')\n",
    "print( 'Train F1 Score: ' + str( metrics.f1_score( y_true = np.reshape(y_train.to_numpy(), (-1, 1)),\n",
    "                                                   y_pred = clf_ridge.predict(X_train_embed) ) ) )\n",
    "print( 'Test F1 Score: ' + str( metrics.f1_score( y_true = np.reshape(y_test.to_numpy(), (-1, 1)),\n",
    "                                                  y_pred = clf_ridge.predict(X_test_embed) ) ) )\n",
    "\n",
    "\n",
    "##\n",
    "## Fit Bernoulli Naive-Bayes\n",
    "print('')\n",
    "print('Bernoulli Naive Bayes')\n",
    "print('')\n",
    "\n",
    "clf_nb = BernoulliNB().fit( X_train_embed, y_train )\n",
    "clf_nb\n",
    "\n",
    "##\n",
    "## Predict on train / test set\n",
    "print( 'Train 0/1 Accuracy: ' + str( np.mean( clf_nb.predict(X_train_embed) == y_train ) ) )\n",
    "print( 'Test 0/1 Accuracy: ' + str( np.mean( clf_nb.predict(X_test_embed) == y_test ) ) )\n",
    "print('')\n",
    "print( 'Train F1 Score: ' + str( metrics.f1_score( y_true = np.reshape(y_train.to_numpy(), (-1, 1)),\n",
    "                                                   y_pred = clf_nb.predict(X_train_embed) ) ) )\n",
    "print( 'Test F1 Score: ' + str( metrics.f1_score( y_true = np.reshape(y_test.to_numpy(), (-1, 1)),\n",
    "                                                  y_pred = clf_nb.predict(X_test_embed) ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5709, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Define model's architecture\n",
    "model = tf.keras.Sequential()\n",
    "model.add( tf.keras.layers.Dense(8, activation='relu', input_shape=(X_train_embed.shape[1],) ) )\n",
    "# model.add( tf.keras.layers.Dense(16, activation='relu' ) )\n",
    "# model.add( tf.keras.layers.Dense(8, activation='relu' ) )\n",
    "# model.add( tf.keras.layers.Dropout(0.2, seed=123) )\n",
    "model.add( tf.keras.layers.Dense(1, activation='sigmoid' ) )\n",
    "\n",
    "##\n",
    "## Compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5709 samples, validate on 1904 samples\n",
      "Epoch 1/20\n",
      "5709/5709 [==============================] - 1s 152us/sample - loss: 0.5917 - accuracy: 0.7502 - val_loss: 0.5121 - val_accuracy: 0.7852\n",
      "Epoch 2/20\n",
      "5709/5709 [==============================] - 0s 43us/sample - loss: 0.4739 - accuracy: 0.7979 - val_loss: 0.4581 - val_accuracy: 0.7936\n",
      "Epoch 3/20\n",
      "5709/5709 [==============================] - 0s 42us/sample - loss: 0.4405 - accuracy: 0.8064 - val_loss: 0.4451 - val_accuracy: 0.7904\n",
      "Epoch 4/20\n",
      "5709/5709 [==============================] - 0s 41us/sample - loss: 0.4280 - accuracy: 0.8075 - val_loss: 0.4401 - val_accuracy: 0.7983\n",
      "Epoch 5/20\n",
      "5709/5709 [==============================] - 0s 40us/sample - loss: 0.4209 - accuracy: 0.8106 - val_loss: 0.4379 - val_accuracy: 0.7978\n",
      "Epoch 6/20\n",
      "5709/5709 [==============================] - 0s 41us/sample - loss: 0.4158 - accuracy: 0.8163 - val_loss: 0.4373 - val_accuracy: 0.7962\n",
      "Epoch 7/20\n",
      "5709/5709 [==============================] - 0s 41us/sample - loss: 0.4121 - accuracy: 0.8171 - val_loss: 0.4396 - val_accuracy: 0.7889\n",
      "Epoch 8/20\n",
      "5709/5709 [==============================] - 0s 41us/sample - loss: 0.4095 - accuracy: 0.8178 - val_loss: 0.4396 - val_accuracy: 0.7920\n",
      "Epoch 9/20\n",
      "5709/5709 [==============================] - 0s 41us/sample - loss: 0.4070 - accuracy: 0.8213 - val_loss: 0.4383 - val_accuracy: 0.7920\n",
      "Epoch 10/20\n",
      "5709/5709 [==============================] - 0s 41us/sample - loss: 0.4048 - accuracy: 0.8196 - val_loss: 0.4386 - val_accuracy: 0.8099\n",
      "Epoch 11/20\n",
      "5709/5709 [==============================] - 0s 41us/sample - loss: 0.4032 - accuracy: 0.8213 - val_loss: 0.4369 - val_accuracy: 0.7983\n",
      "Epoch 12/20\n",
      "5709/5709 [==============================] - 0s 41us/sample - loss: 0.4011 - accuracy: 0.8233 - val_loss: 0.4374 - val_accuracy: 0.8004\n",
      "Epoch 13/20\n",
      "5709/5709 [==============================] - 0s 41us/sample - loss: 0.3994 - accuracy: 0.8247 - val_loss: 0.4380 - val_accuracy: 0.8004\n",
      "Epoch 14/20\n",
      "5709/5709 [==============================] - 0s 42us/sample - loss: 0.3975 - accuracy: 0.8250 - val_loss: 0.4389 - val_accuracy: 0.7983\n",
      "Epoch 15/20\n",
      "5709/5709 [==============================] - 0s 41us/sample - loss: 0.3954 - accuracy: 0.8266 - val_loss: 0.4392 - val_accuracy: 0.7994\n",
      "Epoch 16/20\n",
      "5709/5709 [==============================] - 0s 41us/sample - loss: 0.3938 - accuracy: 0.8257 - val_loss: 0.4396 - val_accuracy: 0.7978\n",
      "Epoch 17/20\n",
      "5709/5709 [==============================] - 0s 48us/sample - loss: 0.3928 - accuracy: 0.8280 - val_loss: 0.4393 - val_accuracy: 0.8025\n",
      "Epoch 18/20\n",
      "5709/5709 [==============================] - 0s 47us/sample - loss: 0.3918 - accuracy: 0.8262 - val_loss: 0.4384 - val_accuracy: 0.8109\n",
      "Epoch 19/20\n",
      "5709/5709 [==============================] - 0s 42us/sample - loss: 0.3901 - accuracy: 0.8282 - val_loss: 0.4410 - val_accuracy: 0.7978\n",
      "Epoch 20/20\n",
      "5709/5709 [==============================] - 0s 42us/sample - loss: 0.3894 - accuracy: 0.8275 - val_loss: 0.4396 - val_accuracy: 0.8114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10837b210>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train Model\n",
    "model.fit(X_train_embed,\n",
    "          y_train,\n",
    "          epochs=20,\n",
    "          validation_data=(X_test_embed, y_test),\n",
    "          verbose=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Net - Fully Connected\n",
      "\n",
      "Train 0/1 Accuracy: 0.8327202662462778\n",
      "Test 0/1 Accuracy: 0.8114495798319328\n",
      "\n",
      "Train F1 Score: 0.7939590075512406\n",
      "Test F1 Score: 0.7652060170045782\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Predict on train / test set\n",
    "print('')\n",
    "print('Neural Net - Fully Connected')\n",
    "print('')\n",
    "\n",
    "# get predictions for in/out of sample\n",
    "preds_train = np.reshape( np.round(model.predict(X_train_embed)), (-1,) )\n",
    "preds_test  = np.reshape( np.round(model.predict(X_test_embed)), (-1,) )\n",
    "\n",
    "print( 'Train 0/1 Accuracy: ' + str( np.mean( preds_train == y_train ) ) )\n",
    "print( 'Test 0/1 Accuracy: ' + str( np.mean( preds_test == y_test ) ) )\n",
    "print('')\n",
    "print( 'Train F1 Score: ' + str( metrics.f1_score( y_true = y_train,\n",
    "                                                   y_pred = preds_train ) ) )\n",
    "print( 'Test F1 Score: ' + str( metrics.f1_score( y_true = y_test,\n",
    "                                                   y_pred = preds_test ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate submission for Kaggle competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>new_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>[happened, terrible, car, crash]</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>[heard, earthquake, different, cities, stay, s...</td>\n",
       "      <td>heard earthquake different cities stay safe ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>[forest, fire, spot, pond, geese, fleeing, acr...</td>\n",
       "      <td>forest fire spot pond geese fleeing across str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>[apocalypse, lighting, spokane, wildfires]</td>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>[typhoon, soudelor, kills, 28, china, taiwan]</td>\n",
       "      <td>typhoon soudelor kills 28 china taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword                                               text  \\\n",
       "0   0     NaN                 Just happened a terrible car crash   \n",
       "1   2     NaN  Heard about #earthquake is different cities, s...   \n",
       "2   3     NaN  there is a forest fire at spot pond, geese are...   \n",
       "3   9     NaN           Apocalypse lighting. #Spokane #wildfires   \n",
       "4  11     NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0                   [happened, terrible, car, crash]   \n",
       "1  [heard, earthquake, different, cities, stay, s...   \n",
       "2  [forest, fire, spot, pond, geese, fleeing, acr...   \n",
       "3         [apocalypse, lighting, spokane, wildfires]   \n",
       "4      [typhoon, soudelor, kills, 28, china, taiwan]   \n",
       "\n",
       "                                            new_text  \n",
       "0                        happened terrible car crash  \n",
       "1  heard earthquake different cities stay safe ev...  \n",
       "2  forest fire spot pond geese fleeing across str...  \n",
       "3              apocalypse lighting spokane wildfires  \n",
       "4             typhoon soudelor kills 28 china taiwan  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtest = textProcessing( test, 'text', cols = ['id','keyword','text','tokenized','new_text'] )\n",
    "newtest.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission_embed = embed( newtest.new_text )\n",
    "submission_preds = np.reshape( np.round(model.predict(submission_embed)), (-1,) )\n",
    "\n",
    "newtest['target'] = submission_preds\n",
    "newtest.target = newtest.target.astype(int)\n",
    "# newtest[['id','target']]\n",
    "newtest[['id','target']].to_csv( '../data/submissions/submission_20200501.csv', index = False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37_ml_lab] *",
   "language": "python",
   "name": "conda-env-py37_ml_lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
